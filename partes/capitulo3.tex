\chapter{DESARROLLO DE PASANTÍAS}
\label{capitulo3}
\lhead{Capítulo 3. \emph{Diseño del sistema}}

\section{Estado del arte}

En esta etapa del proyecto se realizó una investigación sobre los conceptos fundamentales del sistema a implementar. Las definiciones estudiadas fueron: el protocolo HTTP, los URIs, detector de intrusiones (IDS), modelo de Markov y SSM.
El resumen de esta investigación se encuentra en el capítulo \ref{capitulo2} del presente trabajo.

\section{Análisis de Bro}

En esta etapa del proyecto se descargó, se instaló y se estudio la herramienta Bro y su lenguaje de ``scripting''. Bro, es la herramienta principal que se utilizó en la implementación del sistema. Un resumen de esta y de su lenguaje de programación se encuentra en la sección \ref{ssec:Bro}.

\section{Diseño de la arquitectura del sistema}

Esta sección tiene la intención de mostrar la visión general del modelado del sistema que se realizó a partir de las bases teóricas. Aquí, se explicará la arquitectura, el diseño y el modo en el que el IDS basado en SSM interactuará con Bro. Ademas, se detallaran las salidas y los datos de configuración
que va a considerar el sistema para su correcto funcionamiento.

\subsection{Arquitectura del sistema}

La arquitectura del detector de intrusiones que se muestra en el presente trabajo se basa en una arquitectura modular la cual está conformada por tres modulo. Un modulo para realizar la segmentación de los URIs, otro  para realizar la evaluación y un tercero para realizar el entrenamiento.

A grandes rasgos, el módulo de segmentación, se encargará de tomar los URIs previamente filtrados de las solicitudes de tipo HTTP/GET, lo normalizará y lo segmentará de la forma en la que se explicó en el apartado de ``segmentación'' de la sección \ref{sec:delimitadores}.

Por otra parte, el modulo de evaluación se encargará de evaluar la probabilidad de generación de cada uno de los segmentos del URI generados por el módulo de segmentación para al final decidir si el URI de la solicitud enviada al servidor web es anómalo o no.

Por último, el modulo de entrenamiento será el encargado de crear el modelo de normalidad del sistema. Para esto, el sistema recibirá solicitudes libres de ataques e irá calculando la probabilidad de aparición de cada una de las palabras que aparecen en las mismas.

Tanto el modulo de evaluación, como el modulo de entrenamiento son dependientes del modulo de segmentación ya que requieren de los segmentos de URI generados por eso para realizar su trabajo. 

La arquitectura del sistema queda detallada en la figura \ref{fig:arquitectura}.

\begin{figure}[tb]
\begin{center}
\includegraphics[width=3in]{arquitectura.png}
\caption{Arquitectura del sistema.}
\label{fig:arquitectura}
\end{center}
\end{figure}


Así mismo, es importante mencionar que el sistema contará con varios modos de operación que serán explicados a continuación:

\begin{itemize}
\item Modo evaluación: En este modo de operación solo se activarán los módulos de segmentación y evaluación del sistema. A manera general, esta modalidad, se encargará de recibir los URI previamente extraídos de las peticiones de tipo HTTP/GET, segmentarlos a tráves del módulo de segmentación, para luego evaluar si el mismo es anómalo o no
haciendo uso del módulo de evaluación. El funcionamiento de esta modalidad queda detallado en la figura \ref{fig:modoSistema}.
\item Modo entrenamiento ``Online'': En este modo de operación solo trabajaran los módulos de segmentación y entrenamiento. En esta modalidad el módulo de entrenamiento tomará los segmentos arrojados por el módulo de segmentación, calculará la probabilidad de aparición de los mismos para de esta manera ir modificando un modelo de normalidad previamente establecido. El funcionamiento de esta modalidad queda
detallado en la figura \ref{fig:modoSistema}.
\item Modo entrenamiento ``Offline'': Esta modalidad del sistema en análoga al modo de entrenamiento ``Online''. El único aspecto que diferencia a ambas modalidades es que cuando el sistema funciona en modo ``Offline'' no se toma en cuenta, ni se modifica un modelo de normalidad previamente construido. La salida de este modo de entrenamiento sera un modelo de normalidad construido desde cero.El funcionamiento de esta modalidad queda detallado en la figura \ref{fig:modoSistema}.
\end{itemize}

\begin{figure}[tb]
\begin{center}
\includegraphics[width=\linewidth]{modoOperacion.jpeg}
\caption{Modo evaluación (a), modo entrenamiento ``Online'' (b), modo entrenamiento ``Offline'' (c).}
\label{fig:modoSistema}
\end{center}
\end{figure}


\subsection{Filtrado de paquetes HTTP/GET}

Esta funcionalidad se encargará de observar los paquetes de la red y filtrar aquellos de tipo HTTP/GET. Una vez obtenido este tipo de paquetes, esta función extraerá el URI adjunto al mismo.

\subsection{Módulos}

En esta sección se describirán las tareas de cada uno de los módulos que conformar la arquitectura detallada en la figura \ref{fig:arquitectura}, el modo en el que se subdividieron dichas tareas, los datos de entrada y salida, y la interacción que existe entre los mismos.

\subsubsection{Módulo de segmentación}

El modulo de segmentación es un elemento clave dentro de la construcción del IDS basado en SSM, es por eso que su buen diseño e implementación es importante para el buen funcionamiento del sistema. Este se encarga, como se mencionó anteriormente,de tomar el URI que proviene de la solicitud de tipo HTTP/GET que se le hace al servidor HTTP capturado por Bro, normalizarlo y segmentarlo siguiendo las especificaciones que se explicaron en la sección \ref{sec:delimitadores}. 

Es evidente entonces, que este modulo consta de dos funcionalidades fundamentales: la normalización de los URIs y la segmentación.  La normalización se encargará de tomar el URI de las peticiones HTTP/GET entrantes y codificarlo a formato UTF-8. Normalizar es un paso importante dentro del sistema  ya que se estandarizar la forma en las que están escritos los URIs facilita tanto la evaluación como el entrenamiento en el sistema. Por otra parte, la salida arrojada por esta función de normalización será tomada por la de segmentación, quien a su vez se encargará de segmentar el URI de la forma en la que se explica en la sección \ref{sec:delimitadores}, es decir, el URI se dividirá en las diferentes partes estipuladas en el RFC 3986: el ``host'', la ruta, los argumentos, los valores y el ``fragment''.

 En las base teórica, la segmentación de los URIs se realiza mediante un autómata que se encarga de reconocer (realizar un análisis sintáctico) y evaluar en cada uno de sus estados la probabilidad de generación de cada uno de los segmentos.  No obstante, en la función de segmentación del sistema implementado, esta tarea se modeló mediante un analizador sintáctico que hace uso de una gramática (libre de contexto) de atributos que genera el mismo lenguaje que reconoce el autómata presentado en la figura ~\ref{fig:automata}, es decir, el lenguaje de los URI.

En la figura \ref{fig:arquiSegmentacion} se puede apreciar el diagrama de bloques que refleja el funcionamiento del módulo de segmentación.

\begin{figure}[tb]
\begin{center}
\includegraphics[width=3in]{segArquiCompleta.jpeg}
\caption{Diagrama de bloques del módulo de segmentación.}
\label{fig:arquiSegmentacion}
\end{center}
\end{figure}

\subsubsection{Módulo de evaluación}
\label{sec:evaluacion}

El módulo de evaluación, es el encargado de evaluar la probabilidad de generación de cada uno de los segmentos del URI otorgados por el modulo de segmentación, dado un modelo de normalidad. Una vez calculadas estas probabilidades, el modulo se encargará de calcular un índice de anormalidad del URI mediante el uso de las formulas descritas en la sección ~\ref{subsec:exprIndice} para luego compararlo con un parámetro $\theta$ (\ref{eq:ClaseU}) y de este modo saber si los segmentos de URI que ingresaron como entrada posee alguna anormalidad o no. Luego de realizar esta evaluación, el modulo se encargara de escribir los reportes del sistema en un ``log''.

El módulo de evaluación, está conformado por dos grandes funcionalidades: una que se encargará de leer el modelo de normalidad y  otra que calculará el índice de anormalidad y evaluará si el mismo es anómalo o no. 

El modelo teórico que fue explicado en la sección ~\ref{sec:modeloSSM} posee elementos como: un conjunto ``S'' de estados, un conjunto ``O'' de símbolos observables que se encuentran en cada estado, una matriz ``A'' que contiene la probabilidad de transición entre estados, un conjunto ``B'' de vectores que contiene la probabilidad de las palabras observadas en cada estado y un vector de probabilidades iniciales. No obstante, los únicos elementos del modelo que se necesitan ingresar en el sistema para que este funcione y realice las tareas de evaluación son: el conjunto ``O'' de símbolos observables que se encuentra en cada estado y el conjunto de vectores ``B''. El conjunto ``B'' es necesario para resolver la expresión \ref{eq:sumB}. Por otra parte, es necesario hacer uso tanto de ``B'' como ``O'' para obtener el valor de $b_{qtot}$ presentado en la ecuación \ref{eq:Pqtot}. Este elemento es sumamente importante para calcular el índice de anormalidad. Por otra parte, será necesario introducir al sistema los valores de probabilidad de fuera de vocabulario (Poov), ya que son necesarios para obtener el valor de $p_{qtot}$, presente en la ecuación \ref{eq:Pqtot}, en caso que una cadena de caracteres del URI que se esté analizando no se encuentre en el conjunto de observaciones ``O''. Además, se requiere el valor del parámetro $\theta$ para evaluar el índice de anormalidad según lo estipulado en la ecuación \ref{eq:ClaseU} .

    Entonces, en conclusión, los parámetros que requieren ser introducidos al sistema de detección de intrusiones para que este funcione de manera correcta son: el conjunto de observaciones de cada estado (O), el conjunto de vectores de probabilidad de las palabras observadas en cada estado ( $B_{S}, B_{P}, B_{A}, B_{V}$ ), los valores de probabilidad de fuera de vocabulario, es decir $P_{oovS}, P_{oovP}, P_{oovA}, P_{oovV}$ y el valor del parámetro $\theta$. Todos estos parámetros serán leídos por la función de lectura del modulo de evaluación.
    
Una vez leídos los parámetros necesarios para que el sistema funcione, estos serán enviados a la función de evaluación junto a los segmentos de URI dados por el módulo de segmentación. Una vez recibidos los datos de entrada, esta función se encargará de hallar el índice de anormalidad ($N_{s}$) mediante la expresión \ref{eq:Ns} para, de este modo compararlo con el parámetro $\theta$ como se indica en \ref{eq:ClaseU}.No obstante, las tareas de calculo y evaluación del índice de anormalidad, fueron subdivididas a su vez, en cuatro funciones. La primera de las funciones será la encargada de calcular tanto el $\varepsilon_{0}$ que aparece en la expresión \ref{eq:sumB} como la sumatoria de los logaritmos de los $p_{qtot}$ que se encuentra en \ref{eq:Ns}; la segunda función tomará el valor de $\varepsilon_{0}$ y la sumatoria de los logaritmos de los $p_{qtot}$ que calculó la primera función y procederá a efectuar todas las operaciones que hay en la expresión \ref{eq:Ns} para de este modo obtener el índice de anormalidad, $N_{s}$; por otra parte, la tercera función tendrá como tarea comparar el índice de anormalidad $N_{s}$ calculado por la tercera función, con el parámetro $\theta$ como se indica en \ref{eq:ClaseU}; la cuarta será la encargada de escribir en un archivo de texto aquellos URIs anómalos.

El diagrama de bloques presente en la figura \ref{fig:arquiEvaluacion} representa el funcionamiento del módulo de evaluación.

\begin{figure}[tb]
\begin{center}
\includegraphics[width=3in]{evalArqui.jpeg}
\caption{Diagrama de bloques del módulo de evaluación.}
\label{fig:arquiEvaluacion}
\end{center}
\end{figure}

\subsubsection{Módulo de entrenamiento}\label{sec:entrenamiento}

El modelo de normalidad es uno de los aspecto importantes dentro del IDS basado en SSM ya que a partir de la información que este almacena se podrá decidir si un URI es anómalo o no dependiendo de la similitud que posea este con los datos que almacena el modelo. Por esta razón, realizar un modelo de normalidad apropiado es un aspecto  importante para que el módulo de evaluación haga detecciones de intrusiones más certeras.

El módulo encargado de elaborar los modelos de normalidad será el módulo de entrenamiento. A grandes rasgos, este se encargará de recibir un conjunto de segmentos libres de ataques proporcionados por el módulo de segmentación para ir calculando la probabilidad de aparición de cada una de las palabras que aparecen en los mismos, para finalmente, escribir en un archivo toda la información recolectada, es decir, el conjunto de palabras observadas mientras se hacía el entrenamiento, sus probabilidades de aparición y el estado del autómata en el que se observaron las mismas.

Este módulo consta de dos modos: el modo ``Offline'' y el modo ``Online''. La  diferencia fundamental entre el modo ``Online'' y el ``Offline'' es que en el primero necesita como entrada un modelo de normalidad ya construido y los segmentos de URI proporcionados por el módulo de segmentación. Una vez realizado el entrenamiento, esta modalidad se encargará de actualizar el modelo que se leyó al inicio. Por otra parte, el modo ``Online'' solo requiere como entrada los segmentos de URI y como salida proporcionará un  modelo de normalidad construido desde cero.

El modo de entrenamiento ``Offline'' fue dividido en tres funciones. La primera función irá observando los segmentos de los URIs de las peticiones que van llegando y contará el numero de veces que cada segmento fue observado durante el entrenamiento. La segunda función, toma el resultado de las observaciones realizadas por la primera función y calculará la probabilidad de aparición de cada uno de los segmentos haciendo uso de la formula \ref{eq:entrenamiento}. La tercera función tomara los resultados otorgados por la segunda función y los escribirá en un archivo de texto. Este archivo representara el modelo de normalidad construido.

Por otra parte, las tareas a realizar por el modo de entrenamiento ``Online'' fueron divididas de igual modo en tres funciones: La primera función se encargara de leer el modelo de normalidad; la segunda se encargará de tomar el modelo de normalidad leído por la primera función y el conjunto de segmentos de URI del módulo de segmentación. Esta información sera utilizada por la misma para ir calculando la probabilidad de aparición de los segmentos observados. La tercera función se encargara de recibir los resultados obtenidos por la segunda función y actualizara el modelo de normalidad previamente existente.

En la figura \ref{fig:arquiEntrenamiento} se puede apreciar el diagrama de bloques que describe el funcionamiento del módulo de entrenamiento.

\begin{figure}[tb]
\begin{center}
\includegraphics[width=4in]{entrenamArqui.jpeg}
\caption{Diagrama de bloques del módulo de entrenamiento.}
\label{fig:arquiEntrenamiento}
\end{center}
\end{figure}

\section{Implementación del sistema}

Una vez descrita la arquitectura modular del sistema y las funcionalidades asociadas a los diferentes componentes del sistema, en este capítulo se detallarán las cuestiones más relevantes en cuanto a su implementación.
Así, en primer lugar, se describirán como se implementó el filtro de paquetes HTTP/GET, para luego explicar las estructuras de datos utilizadas por cada uno de los módulos; los parámetros de entrada, salida y la implementación de las funciones que los componen.

\subsection{Filtrado de paquetes HTTP/GET}

El módulo de segmentación requiere como entrada los URIs extraidos de las peticiones de tipo HTTP/GET. Esta tarea se realizó haciendo uso de las herramientas brindadas por Bro. En concreto, esta funcionalidad fué implementada con un evento primitivo de Bro llamado ``http request''. Este evento se genera y almacena la información de paquetes HTTP cuando son percibidos por dicha herramienta en la red. Su formato es el siguiente:

\textbf{http request}(c: \textbf{connection}, method: \textbf{string}, original\_URI: \textbf{string},
unescaped\_URI: \textbf{string}, version: \textbf{string})
donde:
\begin{itemize}
\item c: es una estructura de datos de tipo ``connection'' que almacena de manera desglosada la información del mensaje HTTP.
\item method: Es el método extraído de la petición (e.g., GET,POST).
\item original\_URI : URI extraído de la petición (sin decodificar).
\item unescaped\_URI : URI extraído de la petición con todas las codificaciones de porcentaje decodificadas.
\item version: Número de la version HTTP (e.g. 1.1). Este estará especificado en la petición.
\end{itemize}

\subsection{Implementación del modulo de segmentación}

En esta sección, se explicará de manera detallada la implementación del módulo de segmentación y las estructuras de datos utilizadas en el mismo. Este módulo forma parte de los tres que conforman el sistema de detección de intrusiones basado en SSM.

\subsubsection{Estructura de datos}
\label{sssec:estructuraNormalizacion}

En el módulo de segmentación existen tres estructuras de datos fundamentales. Una es utilizada en la función de normalización y la otras dos en
la de segmentación.

\subsubsection*{Normalización}
\label{sssec:estructuraNormalizacion}

La estructura de datos utilizada en la función de normalización es un hash table que contiene los elementos de un encoding table de tipo UTF-8, en donde las claves de la tabla serían los elementos de tipo UTF-8 y los atributos de las mismas corresponderían a los caracteres sin alguna codificación. Con esta tabla, se quiere implementar un diccionario que mapee los elementos de tipo UTF-8 con sus respectivos caracteres lo mas rapido posible.

Se utilizó un hash table para implementar este diccionario debido a que es ampliamente conocido que este tipo de tablas propocionan mucha eficiencia en el tiempo de búsqueda de sus elementos \cite{Cormen}.

Para implementar este tipo de estructura se utilizó el tipo de dato ``table'' otorgado por el lenguaje de scripting de Bro.

\subsubsection*{Función de segmentación}
\label{sssec:estructuraSegmentacion}

Por otra parte, la estructura de datos utilizada en la función de segmentación de este módulo es un registro en el cual se almacenan todos los segmentos que se originan a partir de la segmentación de un URI, el URI sin segmentar, un booleano que informa si el URI segmentado sigue con la sintaxis establecida en el RFC 3896, y el número de estados que fueron visitados en el autómata presentado en el modelo teórico.
 
Se escogió un registro para almacenar la información ya que el lenguaje de ``scripting'' de Bro solo presenta como alternativa el tipo de dato ``record'' para crear un tipo de dato compuesto. 

El registro creado esta conformado por los siguientes campos:
\begin{itemize}
\item uri: Es una variable de tipo ``string'' que almacena el URI sin segmentar. Este campo del registro será utilizado por el módulo de entrenamiento al momento de escribir los logs correspondientes.
\item host: Es una variable de tipo ``hash table'' cuyas claves son número y sus valores  son de tipo string. En esta sección se almacenan los segmentos del URI correspondiente al host.
\item path: Es una variable de tipo ``hash table'' cuyas claves son número y sus valores  son de tipo string. En esta sección se almacenan los segmentos del URI correspondiente al path.
\item query: Es una variable de tipo ``hash table'' cuyas claves y sus valores son de tipo string. En esta sección se almacenan los atributos y los valores del query del URI en caso de que el mismo posea. Los atributos y los valores se almacenarán en una hash table como se mencionó con anterioridad, en donde la clave del mismo serán los atributos del query y en donde los valores de las misma serán los valores del query del URI.
\item fragment: Es una variable de tipo ``string'' que almacenará el fragment del URI en caso de poseerlo.
\item número de estados: es una variable de tipo entero que almacena el número de estados del autómata que se emplea en el módelo teórico fueron visitados para reconocer el URI. Este campo del registro será utilizado por el módulo de evaluación.
\item uri correcto: es una variable de tipo booleano que indica si el URI está sintácticamente correcto o no.
\end{itemize}

El nombre que recibirá este tipo de estructura es ``UriSegmentado''. La misma se puede apreciar gráficamente en la figura \ref{fig:uriSegmentado}.

\begin{figure}[tb]
\begin{center}
\includegraphics[width=4in]{UriSegmentado.jpg}
\caption{Ejemplo gráfico de la estructura ``UriSegmentado''.}
\label{fig:uriSegmentado}
\end{center}
\end{figure}

Además de utilizar el tipo de dato ``UriSegmentado'', el módulo de segmentación hace uso de una estructura de datos compuesta, primitiva del lenguaje de ``scripting'' de Bro llamada  ``URI''. Dicha estructura posee los siguientes campos:

\begin{itemize}
\item scheme: Es un campo opcional de tipo ``string'' que almacena el protocolo del URI.

\item netlocation: Es un campo de tipo ``string'' que almacena el nombre de dominio o la dirección IP del URI.

\item portnum: Es un campo opcional de tipo ``count''  que almacena el número de puerto del URI.
\item path:Es un campo de tipo ``string'' que almacena la ruta del URI.

\item file\_name: En un campo opcional de tipo ``string'' que almacena el nombre completo  del archivo de la ruta del URI junto a su extensión.

\item file\_base: En un campo opcional de tipo ``string'' que almacena el nombre  del archivo de la ruta del URI sin su extensión.

\item file\_ext: En un campo opcional de tipo ``string'' que almacena la extensión del archivo de la ruta.

\item params: Es un campo opcional de tipo ``table'' que almacena todos los parámetros de la consulta del URI. Esta tabla mapea todos los atributos con sus valores.

\end{itemize}

La estructura ``URI'' se puede apreciar gráficamente en la figura \ref{fig:URI}.

\begin{figure}[tb]
\begin{center}
\includegraphics[width=4in]{URIstruct.jpg}
\caption{Ejemplo gráfico de la estructura ``URI''.}
\label{fig:URI}
\end{center}
\end{figure}	

\subsubsection{Función de segmentación}

En la función de segmentación, el problema que se quiere resolver es el siguiente:construir un analizador sintáctico que haga uso de una gramática (libre de contexto) de atributos que genera el mismo lenguaje que reconoce el autómata presentado en la figura 2.4. A nivel de implementación lo que se quiere construir es un analizador sintáctico que verifique que los URIs tengan una estructura sintáctica correcta según los estándares del RFC 3986, y que a la vez vaya almacenando los segmentos, delimitados por los delimitadores presentados en la sección 2.6, en la estructura de datos de la figura 4.2,
detallada en la sección 4.2.1.

A continuación se presentara la forma en que se modeló y se implementó el problema presentado con anterioridad haciendo uso de las herramientas presentadas por el lenguaje de ``scripting'' de Bro.

Para realizar el analizador sintáctico se requiere construir una gramática libre de contexto.

Antes de presentar la gramática se mostrarán los tokens que utilizará la misma como elementos terminales.

Estos tokens utilizarán las expresiones regulares que soporta Bro. Estas están basadas en las expresiones regulares empleadas en Lex, la librería para realizar análisis léxicos del lenguaje de programación C. Estos tokens utilizarán las expresiones regulares que soporta Bro. Estas están basadas en
las expresiones regulares empleadas en Lex, la librería para realizar análisis léxicos del lenguaje de programación C.
La lista de tokens utiliza es la siguiente:

\begin{itemize}
\item protocolo: “http”|”https”
\item host: $(([a-z]+[a-z0-9\-]*[.])?([a-z0-9]+[a-z0-9\-]*[.])+[a-z]{2,3}|localhost)(:([0-9]{1,5}))?|$\\ ((25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.){3}(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)(:([0-9]{1,5}))?
\item elementoPath: [\^?\#]*
\item atributo: [\^\#\&=]
\item valor: [\^\#\&]
\item fragmento: (\#.*)
\end{itemize}

Por otra parte, la gramática libre de contexto en la que está basada la función de análisis sintáctico es la siguiente.

\begin{equation}\label{eq:gramatica}
\begin{aligned}
S -> protocolo “ :// ” H  \\
H -> host “/” P | host \\
P -> P’ “?” Q | P’ “\#” F | P’ \\
Q -> Q’ “\#“ F | Q’ \\
F -> fragment \\
P’ -> \lambda \\
P’ ->  elementoPath \\
P’ -> elementoPath “/” P’ \\
Q’ -> atributo “=” valor \\
Q’ -> atributo “=” valor “\&” Q’ \\
\end{aligned}
\end{equation}

Donde, el elemento de inicio de esta gramática es el símbolo no terminal ``S''

Para almacenar los segmentos en la estructura de datos compuesta de tipo ``uriSegmentado'' que se presentó en la sección ~\ref{sssec:estructuraSegmentacion} a la gramática \ref{eq:gramatica} se le van a asociar atributos a algunas de las reglas de la misma. A este tipo de gramática se le llama gramática de atributos. Los atributos de dicha gramática serán escritos en el lenguaje de scripting de Bro.

\begin{equation}\label{eq:gramaticaAtributos}
\begin{aligned}
S -> protocolo “ :// ” H { uri\$protocolo := protocolo } \\
H -> host “/” P | host { uri\$host := host  } \\
P -> P’ “?” Q | P’ “\#” F | P’ \\
Q -> Q’ “\#“ F | Q’ \\
F -> fragment { uri\$fragment := fragment } \\
P’ -> \lambda  { uri\$path.append(“”) } \\
P’ ->  elementoPath { uri\$path.append(elementoPath) } \\
P’ -> elementoPath “/” P’ { uri\$path.append(elementoPath) } \\
Q’ -> atributo “=” valor { uri\$query[atributo] := valor } \\
Q’ -> atributo “=” valor “\&” Q’ { uri\$query[atributo] := valor } \\
\end{aligned}
\end{equation}

    La gramática de atributos presentada \ref{eq:gramaticaAtributos} representa el modelo de lo que se implementó haciendo uso de Bro.

    Como Bro no cuenta con una librería propia para programar un parser de manera sencilla, se hizo uso de las herramientas con las que cuenta este para procesar cadena de caracteres y expresiones regulares. Las funciones fundamentales que se utilizaron para implementar  la gramática \ref{eq:gramaticaAtributos} fueron: ``split'', ``split\_all'' y ``decompose\_uri''.

A continuación se explicara un poco el funcionamiento de cada una de ellas.

\begin{itemize}
\item split:
La función ``split'' tiene la siguiente forma:

\textbf{split}(str: \textbf{string}, re: \textbf{pattern}) : \textbf{string\_array Attributes:\&deprecated}

Esta función se encarga de dividir una cadena de caracteres de acuerdo a un patrón e introduce el resultado en un arreglo. Por ejemplo, $split"a-b--cd", /(\-)+/)$ retorna $\{"a", "b", "cd"\}.$

Los parámetros de dicha función son:

\begin{itemize}
\item Str:La cadena de caracteres que se quiere dividir. 
\item Re: El patrón que describe lo delimitadores mediante los cuales será dividida la cadena de caracteres. 
\item Retorna: Un arreglo de caracteres donde cada elemento corresponde a una subcadena de caracteres de Str separado por Re.
\end{itemize}

\item split\_all():
Esta función realiza el mismo trabajo que ``split'' con la diferencia que los separadores son incluidos también el parámetro de salida.  Por ejemplo, $split\_all("a-b--cd", /(\-)+/)$ retorna $\{"a", "-", "b", "--", "cd"\}$.

\item decompose\_uri:
La función decompose\_uri tiene la siguiente forma:

\textbf{decompose\_uri}(uri: \textbf{string}) : \textbf{URI}

decompose\_uri dado un URI, retorna una estructura de datos compuesta de tipo URI explicada en la sección ~\ref{sssec:estructuraSegmentacion} que contiene información como el protocolo,la ruta, el número de puerto y los parámetros de las consultas del URI recibido.
\end{itemize}

Por otra parte, para implementar la gramática ~\ref{eq:gramaticaAtributos} se modelaron los elementos no finales de la misma como funciones. Por otra parte, los elementos finales, fueron extraídos haciendo uso de ``split'' y ``split\_all''.

En conclusión, la función encargada de segmentar y realizar el análisis sintáctico del módulo de segmentación posee la siguiente estructura:

\textbf{segmentar}(uri: \textbf{string}) : \textbf{UriSegmentado}.
La función se encargará, de tomar una cadena de caracteres y segmentarla según delimitados por los delimitadores presentados en la sección \ref{sec:delimitadores} y almacenar los mismo en la estructura ``UriSegmentado''.
Los parámetros de dicha función son:
\begin{itemize}
\item url : Cadena de caracteres que será segmentada.
\end{itemize}

\subsubsection{Función de normalización}

La normalización de los URI debe realizarse de acuerdo a las especificaciones establecidas en la Sección 2.6, habiéndose implementado para ello una función denominada ``normalizar'', con el siguiente formato.

\textbf{normalizar}(url: \textbf{string}): \textbf{string} Donde:

\begin{itemize}
\item url: Variable de tipo ``string'' que sera normalizada.
\end{itemize}

Esta función tomará el parámetro de entrada y mediante un ``loop for''
se itera por cada una de las claves de la tabla que se presentó en la sección \ref{sssec:estructuraNormalizacion}. Si alguno de los elementos de la tabla está contenido en el ``string'' que la función recibe como entrada, entonces se procederá a reemplazar el elemento del párametro de entrada por el valor que posee dicha clave en la ``hash table''. Esta tarea de subsitución se realizará haciendo uso de la función ``subst string'' que proporciona Bro.

``subst\_string'' es una función de la forma:

\textbf{subst\_string}(s: \textbf{string}, from: \textbf{string}, to: \textbf{string}) : \textbf{string}
Se encarga de hacer sustituciones en una cadena de caracteres. Los
parámetros de esta son:

\begin{itemize}
\item S:Cadena de caracteres en la que se efectúa la sustitución.
\item From: La cadena de caracteres que se va a buscar en ``S'' para ser
sustituida.
\item To: Cadena de caracteres que pasará a sustituir a ``From''.
\end{itemize}

\subsection{Implementación del módulo de evaluación}

En esta sección se explicará de manera detallada las estructuras de datos utilizadas y la manera en la que se implementó el módulo de evaluación explicado en la sección \ref{sec:evaluacion}  haciendo uso del lenguaje de ``scripting'' de Bro.

\subsubsection{Estructura de datos}

El módulo de evaluación del sistema cuenta con varias estructura de datos compuestas de tipo ``register'' y de tipo ``table'' que serán explicados a continuación 

\subsubsection*{Modelo de normalidad}
\label{sssec:estructuraModelo}

Existen dos estructuras de tipo ``register'' en la función para leer el modelo de normalidad y dos de tipo ``table''.
Las estructuras de tipo ``register'' poseen los siguientes campo:

La primera, cuyo nombre es ``Word'' posee los siguientes campo:
\begin{itemize}
\item ``word'' es un campo de tipo ``string'' en donde se almacenarán las palabras del vocabulario de cada uno de los estados del autómata presentado en la imagen \ref{fig:ssm}.
\item ``state'' es un campo de tipo string en donde se indicará el estado del autómata presentado en la imagen \ref{fig:ssm} al que pertenece la palabra almacenada en el campo ``word''.
\end{itemize}

Esta estructura se puede observar de manera gráfica en la figura \ref{fig:WORD}.

\begin{figure}[tb]
\begin{center}
\includegraphics[width=4in]{Word.jpg}
\caption{Ejemplo gráfico de la estructura ``Word''.}
\label{fig:WORD}
\end{center}
\end{figure}	

La segunda estructura llamada ``Probability'' solo posee un campo llamado ``probability''.
\begin{itemize}
\item ``probability'' es un campo de tipo ``double'' en donde se almacenará la probabilidad de generación de las palabras que se encuentran en el modelo.
\end{itemize}

Se puede observar un ejemplo gráfico de la estructura en la figura \ref{fig:Probability}.

\begin{figure}[tb]
\begin{center}
\includegraphics[width=4in]{Probability.jpg}
\caption{Ejemplo gráfico de la estructura ``Probability''.}
\label{fig:Probability}
\end{center}
\end{figure}	

La tercera estructura de tipo ``register'' que será utilizada en el módulo de evaluación se llamada ``TableDescription'' y pertenece al módulo ``Input'' de Bro y se utilizará al momento de leer los archivos de entrada.
Los campos utilizados de esta estructura fueron los siguientes:
\begin{itemize}
\item source: campo de tipo ``string'' que almacena el nombre del archivo
que va a ser leído.
\item name: campo de tipo ``string'' que almacenará el nombre que se le
asignará al flujo de entrada.
\item destination: Nombre de la tabla que almacena la información contenida
en los archivos.
\item idx: Nombre del registro que definirá los valores que utilizará la tabla que almacena la información del archivo como clave.
\item val: Campo opcional que almacena el nombre del registro que define
los valores de la tabla que almacena la información de los archivos de
entrada.
\end{itemize}

En la figura \ref{fig:TableDescription} se muestra un ejemplo gráfico de ``TableDescription''.

\begin{figure}[tb]
\begin{center}
\includegraphics[width=4in]{TableDescription.jpg}
\caption{Ejemplo gráfico de la estructura ``TableDescription''.}
\label{fig:TableDescription}
\end{center}
\end{figure}	

Por otra parte, las estructuras de tipo ``table'' son dos. Una tabla será utilizada para almacenar las palabras del vocabulario, la probabilidad de generación y el nombre del estado al que pertenece dicha información mientras que la otra almacenará las probabilidades de fuera de vocabulario de cada uno de los estados y el valor del parámetro $\theta$ presente en la expresión \ref{eq:ClaseU}.

La primera tabla es una ``hash table'' que posee dos elementos tipo ``string'' como clave, y como valor tiene un campo de tipo ``Probability''.

Esta tabla almacenará el modelo de normalidad del sistema, es decir, las palabras del vocabulario, la probabilidad de generación de las mismas y el estado al que pertenece dicha información. Las claves de esta tabla serán las palabras del vocabulario y el nombre del estado al que pertenecen. Toda esta informacion será dada a través de un archivo de texto cuya estructura será explicada en las sección ~\ref{sec:lecturaModelo}.

La segunda tabla es una hash table que tendrá solo un elemento como clave de tipo ``string''. Los valores de la misma serán campo tipo ``Valor''. 

En dicha tabla se van a almacenar las probabilidades de fuera de vocabulario de cada uno de los estados del autómata y el parámetro $\theta$. La clave de la misma sería una cadena de caracteres que identifique cada una de las probabilidades  y el parámetro  $\theta$. Esas etiquetas serían las siguientes: Poov1, Poov2, Poov3, Poov4, Theta.  

\subsubsection*{Evaluación de las probabilidades de los URI}
\label{sssec:estructuraEvaluacion}

La función  que se encarga de calcular el índice de anormalidad  y evaluar si el mismo es anómalo o no, solo contiene una estructura compuesta de tipo ``record'' y se utiliza junto a una herramienta de Bro que funciona para escribir ``logs''. Los ``logs'' que son escritos a través de esta herramienta son archivos de texto que contiene una lista de los URI que presentan anomalías.

La estructura lleva como nombre ``InfoAtaque'' y contiene los siguientes campos:

\begin{itemize}
\item clasificacion: es un campo de tipo ``string'' que almacena la clasificación de los URIs anómalos, es decir, aquí se indica si el mismo presenta anomalía por estar sintácticamente mal construidos o porque el índice de anormalidad sobrepasó el parámetro $\theta$.
\item uri: es un campo de tipo ``string'' en el que se va a almacenar el uri que va a ser registrado en el log.
\item probability: es un campo de tipo ``string'' en donde se va a almacenar el valor del índice de anormalidad del uri.
\end{itemize}

Todos los campos anteriormente descritos poseen la cualidad de ser de tipo ``log'' tambien. Con esto se indica cuál de los elementos de la estructura de datos se escribirá sobre los logs.

    El registro ``InfoAtaque'' se puede observar de manera gráfica en la figura \ref{fig:InfoAtaque}. 
    
\begin{figure}[tb]
\begin{center}
\includegraphics[width=4in]{InfoAtaque.jpg}
\caption{Ejemplo gráfico de la estructura ``InfoAtaque''.}
\label{fig:InfoAtaque}
\end{center}
\end{figure}	
    
\subsubsection{Modelo de normalidad en Bro}
\label{sec:lecturaModelo}

En esta sección se explicará cual es el formato de almacenamiento del
modelo de normalidad y los parámetros de configuración, y se explicará como
se implementó la lectura del mismo.

Los elementos que necesitan ser introducidos al módulo de evaluación para su correcto funcionamiento son: el conjunto de observaciones de cada estado (O), el conjunto de vectores de probabilidad de las palabras observadas en cada estado ( $B_{S}, B_{P}, B_{A}, B_{V}$ ), los
valores de probabilidad de fuera de vocabulario ($P_{oovP}, P_{oovA}, P_{oovV}$), y el valor del parámetro $\theta$ (Ec. \ref{eq:ClaseU}).

\subsubsection*{Formato de los archivos de entrada}

    Los parámetros necesarios para el funcionamiento del módulo de evaluación, serán introducidos a tráves de dos archivos, un archivo llamado
``config'' que contendrá los valores de la probabilidad de fuera de vocabulario ($P_{oovP}, P_{oovA}, P_{oovV}$ ) y el valor del parámetro $\theta$ (ec. \ref{eq:ClaseU}) y otro llamado
``modeloBro.log'' en el cual estará el conjunto de observaciones de cada estado junto a sus probabilidades de generación.
   
Tanto el archivo ``config'' como el ``modeloBro.log'' están regidos bajo un formato que establece la herramienta de Bro para leer archivos de entrada.

El formato que establece Bro para los archivos de entrada define que la información se debe introducir en columnas separada mediante tabs, y que debe existir un encabezado al inicio del mismo que inicie abriendo con un numeral (\#) seguido de la palabra ``fields''. Luego de esta palabra se escribirán los nombres que se le asignará a cada columna del archivo.

Por lo tanto, el formato del archivo ``config'' sería como el que se muestra en la figura \ref{fig:archivoConfig}.

\begin{figure}[tb]
\begin{center}
\includegraphics[width=4in]{config.png}
\caption{Formato de archivo ``config''.}
\label{fig:archivoConfig}
\end{center}
\end{figure}	

La primera columna corresponde a las etiquetas que identifican los valores que se encuentran en la segunda columna. Es importante recalcar que los nombres ``Poov1'', ``Poov2'', ``Poov3'', ``Poov4'' y ``Theta'' deben ser escritos en el archivo obligatoriamente de la misma forma en la que aparecen en el ejemplo.

Por otro lado, el formato del archivo ``modeloBro.log'' es el que se muestra en la figura \ref{fig:archivoModeloBro}.

\begin{figure}[tb]
\begin{center}
\includegraphics[width=4in]{modeloBro.png}
\caption{Formato de archivo ``modeloBro.log''.}
\label{fig:archivoModeloBro}
\end{center}
\end{figure}	

La segunda columna de este archivo (``word'') corresponde al conjunto de observaciones ``O'' de cada uno de los estados, mientras que la tercera columna (``probability'') indica la probabilidad de aparición de cada palabra ($B_{S}, B_{P}, B_{A}, B_{V}$). Por otra parte, la primera columna (``state'') indica a que estado del autómata \ref{fig:ssm} pertenece cada palabra y su probabilidad de generación.

Las filas del archivo ``modeloBro.log'' que tienen en la primera columna las palabras: ``numeroPalabraSs'', ``numeroPalabraSp'', ``numeroPalabraSa'', ``numeroPalabraSv'' contienen el número de palabras que han sido procesadas por estado. Esta informacion será utilizada en el entrenamiento en modo offline que será explicado en la sección ~\ref{sec:entrenamientoOffline}.

\subsubsection*{Lectura de los archivos}

Una vez explicado el formato de los archivos que contienen los elementos del modelo y los parámetros necesarios para realizar el cálculo y la evaluación del índice de normalidad de los URIs a evaluar se procederá a explicar el funcionamiento de las funciones encargadas de leer los archivos con la información de entrada.

Para leer dicha informacion se hizo uso del  ``Input Framework'' que otorga Bro como herramienta para leer archivos de entrada. La función utilizada para leer los archivos se llama ``add\_table'' y pertenece al módulo llamado ``Input''.

``add\_table'' se encarga de leer archivos de entrada y almacenar sus datos en una tabla. El formato de esta funcion es el siguiente:\\
%Extraido de : https://www.bro.org/sphinx/frameworks/input.html, https://www.bro.org/sphinx/scripts/base/frameworks/input/main.bro.html\#id-Input::add_table, https://www.bro.org/sphinx/scripts/base/frameworks/input/main.bro.html\#type-Input::TableDescription 
%
\textbf{Input::add\_table}(description: \textbf{Input::TableDescription}) : \textbf{bool} 

Donde ``\textbf{TableDescription}'' es la estructura descrita graficamente en
la figura ~\ref{fig:TableDescription}.

\subsubsection{Evaluación de las probabilidades de los URI}

La función ``evaluacion'' del módulo de evaluación, se encargará de hallar el  índice de anormalidad, dado un conjunto de segmentos de URI, e indicará si el mismo es anómalo o no comparándolo con el valor
de $\theta$, para luego escribir los resultados de la evaluación en un archivo de reportes del sistema. La función implementada que se encargara de realizar las tareas anteriormente descritas tiene el siguiente formato:

\textbf{evaluacion}(uriParsed: \textbf{UriSegmentado}, Bvector: \textbf{table[string,string]
of Probability}, config: \textbf{table[string] of Valor})
donde:
\begin{itemize}
\item uriParsed: es un parámetro de tipo ``UriSegmentado'' (figura \ref{fig:uriSegmentado}), que
almacena los segmentos del URI.
\item Bvector: es una tabla que almacena el conjunto de observaciones de cada estado (O) y el conjunto de vectores de probabilidad de las palabras observadas en cada estado, es decir, $B_{S}, B_{P}, B_{A}, B_{V}$.
\item config: Es una tabla que almacena los diferentes Poov y el valor de $\theta$.
\end{itemize}

No obstante, la tarea realizada por ``evaluacion'' fue subdividida en cuatro funciones: ``epsiloSumatoria'', ``calcularIndiceAnormalidad'',
``evaluarIndiceAnormalidad'' y ``escribirReporte''. La función ``epsiloSumatoria'' se encargará de calcular tanto el $\varepsilon_{0}$ que aparece en la expresión \ref{eq:sumB}
como la sumatoria de los logaritmos de los $p_{qtot}$ que se encuentra en la
expresión \ref{eq:Ns}.

El formato de dicha función es el siguiente:

\textbf{epsiloSumatoria}(segmentos: \textbf{UriSegmentado},
Bvector: \textbf{table[string,string] of Probability}, epsilon : \textbf{double}, estado:\textbf{string}):
\textbf{table[count] of double}

donde los parámetros de entrada serán:
\begin{itemize}
\item segmentos: es un parámetro de tipo ``UriSegmentado'' (figura \ref{fig:uriSegmentado}), que
almacena los segmentos del URI.
\item Bvector: es una tabla que almacena el conjunto de observaciones de cada estado (O) y el conjunto de vectores de probabilidad de las palabras observadas en cada estado, es decir, $B_{S}, B_{P}, B_{A}, B_{V}$.
\item epsilon: Valor correspondiente al Poov.
\item estado: estado del autómata que se esta evaluando (``host'',``path'',``argumentos'',
``valores'').
\end{itemize}

El parámetro de salida correspondería a una tabla que contiene dos elementos: el resultado de la suma de las probabilidades de aparición de las
palabras y la suma del los logaritmos de la probabilidad de aparición.

Por otra parte, ``calcularIndiceAnormalidad'', la encargada de calcular
el  índice de anormalidad $N_{s}$ , tiene el siguiente formato:

\textbf{calcularIndiceAnormalidad}(epsilon0: \textbf{double}, N: \textbf{double}, sumaLogaritmos: \textbf{double}) : double. Donde:

\begin{itemize}
\item epsilon0: Valor de $\varepsilon_{0}$ (expresión \ref{eq:sumB}).
\item N: Valor de ``T'' en la expresión (expresión \ref{eq:sumB}).
\item sumaLogaritmos: Suma de los logaritmos de $p_{qtot}$ que se encuentra en la expresión (expresión \ref{eq:sumB}).
\end{itemize}

El parámetro de salida de esta función será el valor del  índice de anormalidad.

La función, ``evaluarIndiceAnormalidad'' que tiene como tarea comparar el  índice de anormalidad ($N_{s}$) con el parámetro $\theta$, de la forma en que se muestra en la expresión \ref{eq:ClaseU} tiene el siguiente formato:

\textbf{evaluarIndiceAnormalidad}(theta: \textbf{double},indiceAnormalidad: \textbf{double})

donde:
\begin{itemize}
\item theta: Umbral de normalidad ($\theta$).
\item indicesAnormalidad: Índice de anormalidad.
\end{itemize}

La ultima función, ``escribirReporte'', la encargada de escribir en el archivo de reportes la información de los URIs que se han detectado como
anómalos presenta el siguiente formato:

\textbf{escribirReporte}(clasificacion: \textbf{string},
uri: \textbf{string},indiceAnormalidad: \textbf{string})

\begin{itemize}
\item clasificacion: En este campo se informa si el URI es anómalo por sobrepasar el umbral de normalidad o por estar construido de manera
incorrecta sintácticamente.
\item uri: En este campo se introduce el URI que se quiere escribir en el
archivo de salida.
\item indiceAnormalidad: Este campo corresponde al índice de anormalidad.
\end{itemize}

La función anterior fue implementada con la ayuda de las herramientas
que aporta el ``Logging Framework'' de Bro y la estructura de datos ``InfoAtaque'' (fig. ~\ref{fig:InfoAtaque}). La funciones del ``Framework'' utilizadas fueron: ``write'' para escribir sobre el archivo y ``create\_stream'' para crearlo. Ambas pertenecen al modulo ``LOG''. 

El formato que sigue la función ``write'' es el siguiente :

\textbf{LOG::InfoAtaque}(id: \textbf{Log::ID}, columns: \textbf{any}) : \textbf{bool}
Sus parámetros de entrada son:

\begin{itemize}
\item id: Es al ID asociado al archivo sobre el cual se va a escribir.
\item column: Registro que contiene los valores que van a ser escritos en el
archivo.
\end{itemize}

El parámetro de salida de esta función es ``verdadero'' si el archivo fue encontrado y no existieron problemas al momento de la escritura, y ``falso'' de
lo contrario.

Por otra parte, la función ``create\_stream'', esta definida de la siguiente
forma:

\textbf{LOG::create stream}(id: \textbf{Log::ID}, stream: \textbf{Log::Stream}) : \textbf{bool}

Los parámetros de entrada de la misma son:

\begin{itemize}
\item id: Es al ID asociado al archivo sobre el cual se va a escribir.
\item stream: Registro que almacenará la ruta en donde se quiere crear el
archivo y la estructura de dato que se utilizará en la escritura del
archivo.
\end{itemize}

El parámetro de salida de esta función sera ``verdadero'' si se puedo crear el
archivo y ``falso'' si es posible.

\subsection{Implementación del módulo de entrenamiento}

Como se pudo apreciar en la sección \ref{sec:entrenamiento} el modo de entrenamiento cuenta con dos modos: el modo ``Online'' y el modo ``Offline''. En esta se sección, se explicarán las estructuras de datos utilizadas por ambos modos y las funciones implementadas en cada uno de ellos.

\subsubsection{Estructura de datos}
El módulo de entrenamiento consta de varias estructuras de datos de
tipo ``register'' y de tipo ``table'' para realizar su trabajo. Tanto el modo
``Online'' como el ``Offline'' comparten las mismas estructuras.
La estructuras serían las siguientes:
``Entrenamiento'' es una estructura de tipo ``record'', cuyo funcionamiento es ir almacenando el número de veces que una palabra es observada junto con la probabilidad de observación, mientras se realiza el entrenamiento. Los
campos de esta estructura son los siguientes:

\begin{itemize}
\item numPalabras: campo de tipo entero que almacena el número de veces
que una palabra es observada durante el entrenamiento.
\item probability: campo de tipo flotante que almacene la probabilidad de observación de una palabra.
\end{itemize}

Un ejemplo gráfico de la estructura ``Entrenamiento'' se puede apreciar
en la figura \ref{fig:figEntrenamiento}.
La otra estructura de tipo ``record'' es ``Info''. ``Info'' se encargará de
almacenar la información que será escrita en el archivo de texto que representará el modelo de normalidad. Los campos de esta estructura de datos
son los siguientes:

\begin{figure}[tb]
\begin{center}
\includegraphics[width=4in]{EntrenamientoRegister.jpg}
\caption{Ejemplo gráfico de la estructura ``Entrenamiento''.}
\label{fig:figEntrenamiento}
\end{center}
\end{figure}	

\begin{itemize}
\item state: es un campo de tipo ``string'' que almacenará el nombre del
estado al que pertenece la palabra y su probabilidad de observación.
\item word: es un campo de tipo ``string'' que almacenará las palabras observadas durante el entrenamiento.
\item probability: es un campo de tipo flotante que almacenará la probabilidad de observación de las palabras.
\end{itemize}

La estructura ``Info'' se puede observar de manera gráfica en la figura
\ref{fig:figInfo}.

\begin{figure}[tb]
\begin{center}
\includegraphics[width=4in]{Info.jpg}
\caption{Ejemplo gráfico de la estructura ``Entrenamiento''.}
\label{fig:figInfo}
\end{center}
\end{figure}

Por otra parte, la estructura tipo ``table'' que se utilizó en la implementación de este módulo fueron las siguientes:
Se hizo uso de una tabla de hash que posee como clave un campo tipo
``string'' y como valor una estructura de datos de tipo ``Entrenamiento''
(fig. \ref{fig:figEntrenamiento}). Esta tabla tendrá como función almacenar las palabras que van apareciendo durante el entrenamiento, el número de veces que fueron observadas las mismas y la probabilidad de aparición . La clave de esta tabla serán las palabras observadas y el resto de la informacion sería almacenado en la estructura de datos ``Entrenamiento''.
Cada estado del autómata tendrá su tabla de entrenamiento propia para
de esta manera tener una mayor organización de las observaciones realizadas durante el entrenamiento.

\subsubsection{Entrenamiento ``Offline''}

El modo de entrenamiento ``Offline'', es el encargado de crear un modelo de normalidad desde cero.Esta modalidad está conformada por una
función general llamada ``entrenarOffline'', que fué subdividida en tres funciones: ``entrenamientoOffline'',
``evaluarProbabilidad'' y ``escribirArchivoOffline''.

``entrenarOffline'', será la función encargada de llamar el resto de las
funciones, necesarias para realizar el entrenamiento en modo ``Offline''. Su
formato es el siguiente:

\textbf{entrenarOffline}(segmentos: \textbf{UriSegmentado})
donde:

\begin{itemize}
\item segmentos: campo de tipo ``UriSegmentado'' (fig. \ref{fig:uriSegmentado}), que almacena los segmentos de un URI
\end{itemize}

Por otra parte, la función ``entrenamientoOffline'' irá observando los segmentos de los URIs de las peticiones que van llegando y contará el número de veces que cada segmento fue observado durante el entrenamiento. El formato de la misma sigue la siguiente estructura:

\textbf{entrenamientoOffline}(segmentos: \textbf{UriSegmentado}, vocabulario: \textbf{table[string] of Entrenamiento}, estado: \textbf{string})
donde:
\begin{itemize}
\item segmentos: campo de tipo ``UriSegmentado'' (fig. ~\ref{fig:uriSegmentado}), que almacena
los segmentos de un URI (las observaciones).
\item vocabulario: Tabla que contiene una lista de palabras y una lista de
nÚmeros que corresponde al número de apariciones y probabilidad de
aparición de las misma (fig. ~\ref{fig:figEntrenamiento}).
\item numPalabras: Número total de apariciones de todas las palabras vistas durante el entrenamiento de un estado en concreto.
\item estado: estado del autómata que se esta entrenando (``host'', ``path'',
``argumentos'',``valores'').
\end{itemize}

La ``evaluarProbabilidad'' , encargada de tomar el resultado de las observaciones realizadas por ``entrenamientoOffline'' y calcular la probabilidad de aparición de cada uno de los segmentos (ec. \ref{eq:entrenamiento}) tiene el siguiente formato:

\textbf{evaluarProbabilidad}(vocabulario: \textbf{table[string] of Entrenamiento},
numPalabras: \textbf{double})
\begin{itemize}
\item vocabulario: Tabla que contiene una lista de palabras y una lista de
números que corresponde al número de apariciones y probabilidad de
aparición de las misma (fig. ~\ref{fig:figInfo}).
\item numPalabras: Número total de apariciones de todas las palabras vistas durante el entrenamiento de un estado en concreto.
\end{itemize}

Finalmente, ``escribirArchivoOffline'' toma los resultados otorgados por
``evaluarProbabilidad'' y los escribirá en un archivo de texto. El formato de
esta función es el siguiente:

\textbf{escribirArchivoOffline}(vocabulario: \textbf{table[string] of Entrenamiento}, estado: \textbf{string})
donde:
\begin{itemize}
\item vocabulario: Tabla que contiene una lista de palabras y una lista de
números que corresponde al número de apariciones y probabilidad de
aparición de las misma (fig. ~\ref{fig:figInfo}).
\item estado: estado al que pertenece la tabla ``vocabulario''.
\end{itemize}

\subsubsection{Entrenamiento ``Online''}

El modo de entrenamiento ``Online'', encargado de hacer modificaciones a un modelo de normalidad previamente existente fue implementado
haciendo uso de una función llamada ``entrenarOnline'' que a su vez esta
subdividida en tres funciones. Los
nombres que se les dio a estas al momento de ser implementadas fueron:
``entrenamientoOnline'',``escribirArchivoOnline''.

La función ``entrenarOnline'', cuya tarea sera llamar al resto de las funciones del entrenamiento en modo ``Online'' tiene el siguiente formato:

\textbf{entrenarOnline}(uriParsed:\textbf{segmentos::UriSegmentado})
donde:

\begin{itemize}
\item segmentos: campo de tipo ``UriSegmentado'' (fig. \ref{fig:uriSegmentado}), que almacena
los segmentos de un URI
\end{itemize}

Por otra parte, ``entrenamientoOnline'', encargada de calcular la probabilidad de aparición de los segmentos observados haciendo uso de de los segmentos de URI dado por ``entrenarOnline'' y el modelo de normalidad, leído por el módulo de lectura del sistema, sigue el siguiente formato:

\textbf{entrenamientoOnline}(segmentos: \textbf{UriSegmentado},
modelo: \textbf{table[string,string] of Probability}, numPalabras: \textbf{double}, state: \textbf{string})
donde:
\begin{itemize}
\item segmentos: campo de tipo ``UriSegmentado'' (fig. \ref{fig:uriSegmentado}), que almacena los segmentos de un URI.
\item modelo: tabla que almacena el modelo de normalidad previamente
leído.
\item numPalabras:
\item state: nombre del estado al que se le esta realizando el entrenamiento
(``host'',\\``path'',``atributos'',``valores''.
\end{itemize}

Finalmente, ``escribirArchivoOnline'', se encargará de recibir todos los
resultados obtenidos del entrenamiento para escribirlos sobre un archivo de
texto. El formato de esta función es:

\textbf{escribirArchivoOnline}(vocabulario: \textbf{table[string,string] of Probability})
donde:
\begin{itemize}
\item vocabulario: Es una tabla que almacena los resultados del entrena-
miento.
\end{itemize}

\section{Evaluación y pruebas}

En el presente capítulo se explicará las pruebas funcionales y operativas
realizadas al sistema. Así como las bases de datos utilizadas para realizar
las mismas.

\subsection{Base de datos}\label{ssec:DB}

Las bases de datos utilizadas por las pruebas fueron trazas capturadas
en servidores web. Para capturar estos paquetes de tipo HTTP los pasos a
seguir fueron los siguientes:

\begin{enumerate}
\item Se instaló una aplicación de servicio web en el ordenador.
\item Se corrió una aplicación web en la aplicación anteriormente instalada.
\item Se empezaron a hacer solicitudes a la aplicación web a tráves de otro
dispositivo. Mientras esto ocurria, ``Wireshark'' realizaba las capturas
de los paquetes de la red.
\end{enumerate}
Se obtuvo cuatro bases de datos:
\begin{itemize}
\item db1.pcap: Capturas de paquetes provenientes de las solicitudes reali-
zadas a una aplicación web, A.
\item db2.pcap: Capturas de paquetes provenientes de la misma aplicación
web A.
\item db3.pcap: Capturas de paquetes provenientes de una aplicación web,
B.
\item db4.pcap: Capturas de paquetes descargadas de: \cite{wireshark}.
\end{itemize}

\subsection{Pruebas funcionales}

En esta sección se explicarán las pruebas funcionales aplicadas a cada
una de la funciones construidas en el sistema.

\subsubsection{Filtro HTTP/GET}

Para probar el filtro de tipo HTTP/GET se tomó la base de datos,
\textbf{db1.pcap}, que contiene tanto paquetes HTTP/GET, como paquetes correspondientes a la sesión HTTP. La prueba consistió en pasarle a la función construida la base de datos de paquetes para que esta imprimiera los URIs de las peticiones HTTP/GET que estuviesen contenidas en la misma. En la
figura \ref{fig:filtroHTTP} se muestra un esquema de la prueba que se realizó.

\begin{figure}[tb]
\begin{center}
\includegraphics[width=2in]{filtroHTTP.png}
\caption{Esquema de pruebas realizadas al filtro HTTP/GET.}
\label{fig:filtroHTTP}
\end{center}
\end{figure}

\subsubsection{Lectura de archivos}

La lectura de los archivos es de suma importancia, ya que el sistema utiliza un modelo de normalidad y un conjunto de parámetros que se introducen
al mismo a tráves de archivos.
La manera en la que se probó esta función consistió en leer ambos archivos de textos necesarios por el sistema: ``config'' y ``modeloBro.log'' y luego se imprimieron las tablas resultantes de la lectura de los mismos.
En la figura \ref{fig:configFile}, se puede observar el archivo ``config'' que leerá la función de lectura del sistema y en la figura \ref{fig:configResult}, se puede apreciar la forma en la
que la misma almacenó los datos en la tabla correspondiente.
Por otra parte, en la figura \ref{fig:modelFile}, está el archivo ``modeloBro.log'' que fué utilizado en la prueba realizada, mientras que en la figura \ref{fig:modelResult} se muestra el resultado arrojado por la misma.

\begin{figure}[tb]
\begin{center}
\includegraphics[width=3in]{configFile.jpg}
\caption{Archivo ``config''.}
\label{fig:configFile}
\end{center}
\end{figure}

\begin{figure}[tb]
\begin{center}
\includegraphics[width=3in]{tablaConfig.png}
\caption{Tabla que contiene información del archivo ``config''.}
\label{fig:configResult}
\end{center}
\end{figure}

\begin{figure}[tb]
\begin{center}
\includegraphics[width=3in]{modeloOffline.jpg}
\caption{Archivo ``modeloBro.log''.}
\label{fig:modelFile}
\end{center}
\end{figure}

\begin{figure}[tb]
\begin{center}
\includegraphics[width=3in]{tablaModeloBro.png}
\caption{Tabla que contiene información del archivo ``modeloBro.log''.}
\label{fig:modelResult}
\end{center}
\end{figure}

\subsubsection{Módulo de segmentación}

Como se mencionó en los secciones anteriores, el modulo de segmentación
cuenta con dos funciones principales: la función de normalización y la de
segmentación. A continuación se mostrará la manera en la que se probó cada una de las funciones.

\subsubsection*{Función de normalización}

Las pruebas realizadas a la función de normalización consistió en realizar una lista de URIs sin normalizar, ingresarlos como parámetros a la función y observar los resultados arrojados por la misma.
La lista de URIs utilizados en esta prueba se pueden observar en la figura \ref{fig:uriSinNorm}. Por otra parte, los resultados arrojados por la misma se muestran en la
figura \ref{fig:uriNorm}.

\begin{figure}[tb]
\begin{center}
\includegraphics[width=3in]{uriSinNorm.png}
\caption{URIs sin normalizar.}
\label{fig:uriSinNorm}
\end{center}
\end{figure}

\begin{figure}[tb]
\begin{center}
\includegraphics[width=3in]{uriNorm.png}
\caption{URIs normalizados.}
\label{fig:uriNorm}
\end{center}
\end{figure}

\subsubsection*{Función de segmentación}

La pruebas realizadas a la función de segmentación, consistieron en ingresarle un conjunto de URIs a la misma y observar la manera en la que
esta los segmentaba.

\subsubsection{Módulo de entrenamiento}
\subsubsection*{Modo ``Offline''}
Como se pudo observar en los secciones anteriores, el módulo de entrenamiento esta conformado por una función, ``entrenarOffline'', que que se
encarga de hacer la llamada a función de: ``entrenamientoOffline'', ``evaluarProbabilidad'', ``escribirArchivoOffline''.
Para probar la función, ``entrenamientoOffline'', se construyeron una serie de datos de tipo ``UriSegmentado'' (fig. \ref{fig:uriSegmentado}), provenientes de la base de datos \textbf{db3.pcap} y le fueron pasados como parámetro de entrada a la misma. Una vez procesados los datos, se observó la salida de la misma para verificar la correctitud.

Por otra parte, para probar la función ``evaluarProbabilidad'', se tomaron los resultados arrojados por ``entrenamientoOffline'' y se
observó el resultado que arrojaba la misma. 

La prueba que se le realizó a ``escribirArchivoOffline'', consistió en tomar el resultado arrojado por ``evaluarProbabilidad'' y observar el
archivo de salida que escribía dicha función. 

\subsubsection*{Modo ``Online''}
Al igual que el modo ``Offline'', el modo ``Online'' esta conformado por
una función,``entrenarOnline'', que se encarga de hacer la llamada a función
del resto:``entrenamientoOnline'',``escribirArchivoOnline''
Las pruebas de ``entrenamientoOnline'' consistieron en darle un modelo de normalidad y un conjunto de estructura
de tipo ``UriSegmentado'' y observar la salida que arrojaba la misma.

Para probar la función ``escribirArchivoOnline'', se tomó el resultado arrojado por ``entrenamientoOnline'' y se observó el archivo de salida escrito por la misma.
\subsubsection{Módulo de evaluación}

El modulo de evaluación consta de una función general, llamada ``evaluacion'' que se encarga de hacer la llamada a función de: ``epsiloSumatoria'',
``calcularIndiceAnormalidad'', ``evaluarIndiceAnormalidad'' y ``escribirReporte'', que a su vez se encargan de realizar el trabajo del módulo de evaluación.
Para probar la función ``epsiloSumatoria'', se ingresó un conjunto de datos de tipo de tipo ``UriSegmentado'', un modelo de normalidad previamente leído, un valor para el epsilon, y un conjunto de estado del autómata para observar los resultados que arrojaba la misma.
Para la prueba de la función ``calcularIndiceAnormalidad'', se tomaron
los resultados proporcionados por la función ``epsiloSumatoria'' y se observará el resultado obtenido.

Tanto los resultados obtenidos por ``epsiloSumatoria'' por ``calcularIndiceAnormalidad'' fueron verificados calculando de manera manual los valores
que estas funciones calculan, haciendo uso de las expresiones correspondientes.
Las pruebas de la función ``evaluarIndiceAnormalidad'' consistieron en
darle un  índice de anormalidad y un valor del parámetro $\theta$, como los que
se muestran en la figura \ref{fig:archivoConfig} y verificar si la misma clasificaba de manera adecuada.
Finalmente, para realizar la prueba de ``escribirReporte'' se le pasó una serie de URIs pertenecientes a la base de datos \textbf{db1.pcap}. Una vez realizado
esto, se observó el archivo de salida escrito por dicha función.

\subsection{Pruebas operativas}

En esta sección se explicaran las pruebas operativas que se les aplicaron
a las tres modalidades del sistema implementado.

\subsubsection{Modo entrenamiento ``Offline''}

Para probar el modo ``Offline'' del sistema, se tomó la base de datos \textbf{db3.pcap} explicada en la sección \ref{ssec:DB}, y se le ingresó al sistema configurado en modo ``Offline''. Una vez realizado esto, se observó el modelo de
normalidad arrojado por dicha modalidad.
En la figura \ref{fig:modeloOffline} se puede apreciar el modelo de normalidad obtenido
por la misma.

\begin{figure}[tb]
\begin{center}
\includegraphics[width=4in]{modeloOffline.jpg}
\caption{Modelo de normalidad obtenido en el modo ``Offline''.}
\label{fig:modeloOffline}
\end{center}
\end{figure}

\subsubsection{Modo entrenamiento ``Online''}

El modo ``Online'' del sistema fue probado ingresando la base de datos \textbf{db4.pcap} explicada en la sección \ref{ssec:DB} al sistema junto con el modelo mostrado en la figura \ref{fig:modeloOffline}. Una vez realizado esto, se observo la salida y se pudo verificar que, en efecto el modelo antiguo fue modificado. En la figura \ref{fig:modeloOnline} se puede apreciar la salida de esta modalidad tras la prueba realizada.

\begin{figure}[tb]
\begin{center}
\includegraphics[width=4in]{modeloOnline.jpg}
\caption{Modelo de normalidad obtenido en el modo ``Online''.}
\label{fig:modeloOnline}
\end{center}
\end{figure}

\subsubsection{Modo evaluación}

Para realizar la prueba del modo de evaluación se tomó la base de datos
\textbf{db1.pcap} para realizar un modelo de normalidad haciendo uso del modo de entrenamiento ``Offline''. De esta manera, se evaluarán las trazas que se encuentran en la base de datos, \textbf{db2.pcap} y \textbf{db3.pcap} y se observaran los resultados obtenidos.
La intención de esta prueba es comparar los  índices de anormalidad
obtenidos por la base de datos \textbf{db2.pcap} y \textbf{db3.pcap}.
Como la base de datos \textbf{db2.pcap} posee el mismo comportamiento que
el del modelo de normalidad por pertenecer a peticiones realizadas al mismo servidor, se espera que los  índices de anormalidad sean mas bajos que los obtenido por \textbf{db3.pcap}, ya que esta trazas pertenecen a peticiones que no se encuentran registradas en el comportamiento del modelo de normalidad.
En la figura \ref{fig:indicesMalos} se muestran los resultados de los  índices de anormalidad calculados cuando se evalúa la base de datos \textbf{db3.pcap}.
Se puede observar que los índices oscilan entre 25 y 36.
Por otra parte, en la figura \ref{fig:indicesBuenos} se pueden detallar los índices de anormalidad resultantes, de evaluar la base de datos \textbf{db2.pcap}.Se puede apreciar que los índices de anormalidad de la figura \ref{fig:indicesBuenos} son mas bajos que los de la figura \ref{fig:indicesMalos}. Estos resultados son los esperados, ya que \textbf{db2.pcap} no presenta incongruencias con el modelo de normalidad construido, mientras que la base de dato \textbf{db3.pcap} si. Por lo tanto es conveniente que el sistema lo catalogue como anomalías.
Un parámetro $\theta$, óptimo para esta prueba en particular, debería ser un
valor que sea menor que 25 y mayor que 18.

\begin{figure}[tb]
\begin{center}
\includegraphics[width=4in]{indicesMalos.png}
\caption{Índices de anormalidad obtenidos de db3.pcap.}
\label{fig:indicesMalos}
\end{center}
\end{figure}

\begin{figure}[tb]
\begin{center}
\includegraphics[width=4in]{indicesBuenos.jpg}
\caption{Índices de anormalidad obtenidos de db2.pcap.}
\label{fig:indicesBuenos}
\end{center}
\end{figure}