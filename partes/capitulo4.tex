\chapter{Detalles de implementación}

En el capítulo anterior se pudo apreciar la arquitectura del IDS que se desea implementar haciendo uso del lenguaje de scripting de Bro. Allí se pudo observar que el mismo está constituido básicamente por tres módulos fundamentale: un módulo de segmentación que se encarga de normalizar y segmentar el URI. Un módulo de evaluación que se encargará de evaluar la probabilidad de generación de un URI dado un modelo de normalidad para así clasificar el mismo como normal o anormal y un módulo de entrenamiento cuyo trabajo será crear modelos de normalidad dados un conjunto significante de URI sin alguna anormalidad.

A continuación se explicará las estructuras de datos utilizadas y como se realizó la implementación de cada uno de los módulos mencionados anteriormente haciendo uso de las herramientas presentadas por el lenguaje de scripting de Bro.

\label{capitulo4}
\lhead{Capítulo 4. \emph{Detalles de implementación}}
\section{Implementación del modulo de segmentación}

A continuación se explicará de manera detallada la implementación del módulo de segmentación y las estructuras de datos utilizadas en el mismo. Este módulo forma parte de los tres que conforman el sistema de detección de intrusiones basado en SSM. En el capítulo anterior se pudo apreciar la arquitectura del módulo de segmentación. Además, se pudo observar que el mismo consta de dos funcionalidades fundamentales: la normalización de los URIs y la segmentación. A grandes rasgos, la normalización se encargará de tomar el URI de las peticiones HTTP entrantes y codificarlo a formato UTF-8, el output arrojado por esta función será tomado por la de segmentación, quien a su vez se encargará de segmentar el URI de la forma en la que se explica en la sección (inserte número de la sección), es decir, el URI se dividirá en las diferentes partes estipuladas en el RFC (insertar número del RFC): el host, el path, los argumentos, los valores y el fragment. Estos segmentos obtenidos luego ser almacenados en una estructura de datos global para que de esta forma, la información obtenida pueda ser utilizada por el resto de los módulos.

La implementación de la función de normalización que se explicará a continuación está basada en el uso de una hashtable con todos los elementos de una encoding table de tipo UTF-8. Por otra parte, la función de segmentación que teóricamente esta basada en un autómata que reconoce el lenguaje de los URI se implementará tomando la inspiración de una gramática que genere el mismo lenguaje que reconoce el autómata (el lenguaje de los URIs). Esto se puede realizar ya que las gramáticas poseen el mismo nivel de expresividad que un autómata, como se mostrará en la secciones próximas. Además, las herramientas presentadas por el lenguaje de scripting Bro facilitan la implementación de un segmentador inspirado en una gramática.

\subsection{Estructura de datos}
En el módulo de segmentación existen dos estructuras de datos fundamentales. Una es utilizada en la función de normalización y la otra en la de segmentación.

\subsubsection{Función de normalización}
\label{sssec:estructuraNormalizacion}

La estructura de datos utilizada en la función de normalización es un hashtable que contiene los elementos de un encoding table de tipo UTF-8, en donde las claves de la tabla serían los elementos de tipo UTF-8 y los atributos de las mismas corresponderían a los caracteres sin alguna codificación, ya que lo que se quiere es un diccionario que mapee los elementos de tipo UTF-8 con sus respectivos caracteres lo mas rapido posible.

Se utilizó un hash table para implementar este diccionario debido a que es ampliamente conocido que este tipo de tablas propocionan mucha eficiencia en el tiempo de búsqueda de sus elementos, como lo explica Cormen en su libro: "Introduction to Algoriths":

“Una hash table es una estructura de datos efectiva para implementar diccionarios. A pesar de que la búsqueda de un elemento en una hash table puede tomar el mismo tiempo de búsqueda que una lista enlazada - O(n)/tiempo en el peor de los casos - en la práctica, el mapeo funciona extremadamente bien.  Bajos suposiciones razonable, el tiempo de búsqueda promedio de una hash table es de O(1)”.

Para implementar este tipo de estructura se utilizó el tipo de dato “table” otorgado por el lenguaje de scripting de Bro. Un ejemplo concreto de como luce la estructura de dato implementada en Bro se mostrará a continuación:

\begin{verbatim}
global encoding : table[string] of string = {    ["%21"] =    "!"     ,
                                                ["%22"] =    "”"    ,                                        
                                                ["%23"] =    "#"    ,
                                                ["%24"] =    "$"    }
\end{verbatim}

La funcionalidad de esta tabla de codificación será explicada en la sección (insertar sección de implementación de normalización)

\subsubsection{Función de segmentación}
\label{sssec:estructuraSegmentacion}

Por otra parte, la estructura de datos utilizada en la función de segmentación de este módulo es un registro en el cual se almacenan todos los segmentos que se originan a partir de la segmentación de un URI, el URI sin segmentar, un booleano que informa si el URI segmentado sigue con la sintaxis establecida en el RFC (insertar número del RFC), y el número de estados que fueron visitados en el autómata presentado en el modelo teórico (insertar número de imagen) para reconocer al mismo .

En Bro existen las palabras claves “record” y “type” y se utilizan de forma similar en las que se emplean las palabras claves “typedef” y “struct” en C. Con estas palabras, Bro permite combinar nuevos tipos de datos y crear tipos de datos compuestos para adaptarse a las necesidades de la situación. A continuación, se mostrará un ejemplo de un tipo de dato compuesto escrito en Bro.

Extraído de la documentación de Bro.

\begin{verbatim}
type Service: record {
    name: string;
    ports: set[port];
    rfc: count;
};
\end{verbatim}
Cuando se combina la palabra clave “type”, el registro puede generar un tipo de dato compuesto.

Se escogió un registro para almacenar la información ya que el lenguaje de scripting de Bro solo presenta como alternativa el tipo de dato “record” para crear un tipo de dato compuesto. Es necesario crear este tipo de dato ya que se requiere una estructura que almacene los diferentes tipos de datos de los que se hablaron anteriormente. 

El registro creado esta conformado por los siguientes campos:
\begin{itemize}
\item uri: Es una variable de tipo string que almacena el URI sin segmentar. Este campo del registro será utilizado por el módulo de entrenamiento al momento de escribir los logs correspondientes.
\item host: Es una variable de tipo hash table cuyas claves son número y sus valores  son de tipo string. En esta sección se almacenan los segmentos del URI correspondiente al host.
\item path: Es una variable de tipo hash table cuyas claves son número y sus valores  son de tipo string. En esta sección se almacenan los segmentos del URI correspondiente al path.
\item query: Es una variable de tipo hash table cuyas claves y sus valores son de tipo string. En esta sección se almacenan los atributos y los valores del query del URI en caso de que el mismo posea. Los atributos y los valores se almacenarán en una hash table como se mencionó con anterioridad, en donde la clave del mismo serán los atributos del query y en donde los valores de las misma serán los valores del query del URI.
\item fragment: Es una variable de tipo string que almacenará el fragment del URI en caso de poseerlo.
\item número de estados: es una variable de tipo entero que almacena el número de estados del autómata que se emplea en el módelo teórico fueron visitados para reconocer el URI. Este campo del registro será utilizado por el módulo de evaluación.
\item uri correcto: es una variable de tipo booleano que indica si el URI está sintácticamente correcto o no.
\end{itemize}

El uso de esta estructura y el de cada uno de sus campos se explicara a detalle en las sección (introducir número de la sección de la implementación del autómata).

Además de utilizar el tipo de dato “uriSegmentado”, el módulo de segmentación hace uso de una estructura de datos compuesta, primitiva del lenguaje de scripting de Bro llamada  “URI”. Dicha estructura posee los siguientes campos:

\begin{itemize}
\item scheme: Es un campo opcional de tipo “string” que almacena el protocolo del Uri.

\item netlocation: Es un campo de tipo “string” que almacena el nombre de dominio o la dirección IP del Uri.

\item portnum: Es un campo opcional de tipo “count”  que almacena el número de puerto del uri.
path:Es un campo de tipo “string” que almacena la ruta del uri.

\item $file_name$: En un campo opcional de tipo “string” que almacena el nombre completo  del archivo de la ruta del uri junto a su extensión.

\item $file_base$: En un campo opcional de tipo “string” que almacena el nombre  del archivo de la ruta del uri sin su extensión.

\item $file_ext$: En un campo opcional de tipo “string” que almacena la extensión del archivo de la ruta.

\item params: Es un campo opcional de tipo “table” que almacena todos los parámetros de la consulta del uri. Esta tabla mapea todos los atributos con sus valores.
\end{itemize}

\subsection{Implementación del automata de reconocimiento de URIs}

En la función de segmentación, el problema que se quiere resolver es el siguiente: dado un URI lo que se quiere hacer es guardar los segmentos delimitados por los delimitadores presentados en la sección ~\ref{sec:delimitadores} en la estructura de datos detallada en la sección ~\ref{sssec:estructuraSegmentacion} del URI, y a la vez verificar que el mismo tenga una estructura sintáctica correcta según los estándares del RFC 3986. 

En las base teórica, este trabajo es realizado mediante un autómata que se encarga de reconocer y evaluar en cada uno de sus estados la probabilidad de generación de cada uno de los segmentos. 

La tarea de esta sección es explicar la forma en que se modeló y se implementó el autómata que en el ámbito teórico del SSM es el encargado de realizar la segmentación del URI, haciendo uso de las herramientas presentada por el lenguaje de scripting de Bro.

Entonces básicamente existen dos tareas fundamentales dentro de esta función: segmentar y realizar un análisis sintáctico. En programación cuando se tiene un conjunto de datos de entrada, que en este caso sería el URI, y se desea realizar un análisis sintáctico sobre el mismo, lo más común es implementar un analizador sintáctico o parser.

El análisis realizado por un analizador sintáctico “es el proceso en el cual se estudia la manera en la que una cadena de caracteres terminales es generado por una gramática.”  Compiler, principle, techniques and tools."

Por otra parte, existen varios tipos de gramáticas, las gramáticas libre de contexto y las gramáticas regulares. Las que se suelen utilizar en un analizador sintáctico son las gramáticas libres de contexto. Una gramática libre de contexto “en el contexto del lenguaje natural, sería un conjunto de reglas que son utilizadas para construir o validar oraciones” “Formal Languages and Automata Theory” de D. Goswami and K. V. Krishna. 

De manera más formal, según la definición 3.1.1 de: “Formal Languages and Automata Theory” de D. Goswami and K. V. Krishna. Se puede decir que una gramática libre de contexto es una  cuádrupla G = (N, $\sum$, P, S), donde:
\begin{enumerate}
\item N es un conjunto de no-terminales,
\item $\sum$ es un conjunto de terminales. Los terminales son elementos fundamentales en el lenguaje generado por la gramática.
\item S $\in$ N es el símbolo de inicio.
\item P es un subconjunto finito de N x V * llamado el conjunto de reglas de producciones. Aquí, V = N U $\sum$."
\end{enumerate}

Entonces, para realizar el analizador sintáctico se requiere construir una gramática libre de contexto que genere el mismo lenguaje que reconoce el autómata presentado en la imagen ~\ref{fig:automata}, es decir, el lenguaje de los URI.

Antes de presentar la gramática se mostrarán los tokens que utilizará la misma como elementos terminales. Un token “es la cadena de caracteres más corta que posee algún significado” Scott, Compilers.

Estos tokens utilizarán las expresiones regulares que soporta Bro. Estas están basadas en las expresiones regulares empleadas en Lex, la librería para realizar análisis léxicos del lenguaje de programación C.

\begin{itemize}
\item protocolo: “http”|”https”
\item host: $(([a-z]+[a-z0-9\-]*[.])?([a-z0-9]+[a-z0-9\-]*[.])+[a-z]{2,3}|localhost)(:([0-9]{1,5}))?|$\\ ((25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.){3}(25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)(:([0-9]{1,5}))?
\item elementoPath: [\^?\#]*
\item atributo: [\^\#\&=]
\item valor: [\^\#\&]
\item fragmento: (\#.*)
\end{itemize}

La gramática libre de contexto en la que está basada la función de análisis sintáctico es la siguiente.

\begin{equation}\label{eq:gramatica}
\begin{aligned}
S -> protocolo “ :// ” H  \\
H -> host “/” P | host \\
P -> P’ “?” Q | P’ “\#” F | P’ \\
Q -> Q’ “\#“ F | Q’ \\
F -> fragment \\
P’ -> \lambda \\
P’ ->  elementoPath \\
P’ -> elementoPath “/” P’ \\
Q’ -> atributo “=” valor \\
Q’ -> atributo “=” valor “\&” Q’ \\
\end{aligned}
\end{equation}

Donde, el elemento de inicio de esta gramática es el símbolo no terminal “S”

Para almacenar los segmentos en la estructura de datos compuesta que se presentó en la sección ~\ref{sssec:estructuraSegmentacion} a la gramática \ref{eq:gramatica} se le van a asociar atributos a algunas de las reglas de la misma. A este tipo de gramática se le llama gramática de atributos. Los atributos de dicha gramática serán escritos en el lenguaje de scripting de Bro.

\begin{equation}\label{eq:gramaticaAtributos}
\begin{aligned}
S -> protocolo “ :// ” H { uri\$protocolo := protocolo } \\
H -> host “/” P | host { uri\$host := host  } \\
P -> P’ “?” Q | P’ “\#” F | P’ \\
Q -> Q’ “\#“ F | Q’ \\
F -> fragment { uri\$fragment := fragment } \\
P’ -> \lambda  { uri\$path.append(“”) } \\
P’ ->  elementoPath { uri\$path.append(elementoPath) } \\
P’ -> elementoPath “/” P’ { uri\$path.append(elementoPath) } \\
Q’ -> atributo “=” valor { uri\$query[atributo] := valor } \\
Q’ -> atributo “=” valor “\&” Q’ { uri\$query[atributo] := valor } \\
\end{aligned}
\end{equation}

    La gramática de atributos presentada \ref{eq:gramaticaAtributos} representa el modelo de lo que se implementó haciendo uso de Bro.

    Como Bro no cuenta con una librería propia para programar un parser de manera sencilla, se tuvo que hacer uso de las herramientas con las que cuenta este para procesar cadena de caracteres y expresiones regulares. Las funciones fundamentales que se utilizaron para implementar  la gramática \ref{eq:gramaticaAtributos} fueron: “split”, “split\_all” y decompose\_uri.

Entonces,lo que se hizo para implementar la gramática ~\ref{eq:gramaticaAtributos} fue modelar los elementos no finales de la misma como funciones en Bro. Los elementos finales, por otra parte fueron extraídos haciendo uso de “split” y “split\_all”. A continuación se explicara un poco el funcionamiento de cada una de ellas.

\begin{itemize}
\item split:
La función “split” tiene la siguiente forma
function(str: string, re: pattern) : string\_array Attributes:\&deprecated

Esta función se encarga de dividir una cadena de caracteres de acuerdo a un patrón e introduce el resultado en un arreglo. Por ejemplo, $split"a-b--cd", /(\-)+/)$ retorna $\{"a", "b", "cd"\}.$

Los parámetros de dicha función son:

\begin{itemize}
\item Str:La cadena de caracteres que se quiere dividir. 
\item Re: El patrón que describe lo delimitadores mediante los cuales será dividida la cadena de caracteres. 
\item Retorna: Un arreglo de caracteres donde cada elemento corresponde a una subcadena de caracteres de Str separado por Re.
\end{itemize}

\item split\_all():
Esta función realiza el mismo trabajo que “split” con la diferencia que los separadores son incluidos también el parámetro de salida.  Por ejemplo, $split\_all("a-b--cd", /(\-)+/)$ retorna $\{"a", "-", "b", "--", "cd"\}$.

\item decompose\_uri:
La función decompose\_uri tiene la siguiente forma: function(uri: string) : URI

decompose\_uri dado un URI, retorna una estructura de datos compuesta de tipo URI explicada en la sección ~\ref{sssec:estructuraSegmentacion} que contiene información como el protocolo,la ruta, el número de puerto y los parámetros de las consultas del URI recibido.
\end{itemize}

A continuación, se mostrará un pseudocódigo en donde se podrá apreciar de manera más clara el procedimiento llevado a cabo para implementar la grámatica \ref{eq:gramaticaAtributos} haciendo uso de las funciones nombradas con anterioridad.

\begin{verbatim}
# Hace el trabajo que realiza el símbolo no terminal "S" de la gramática
function inicio(url: string){
    # Se parsea el protocolo
    local test_pattern = /(http(s)?:\/\/)?/;
    local results = split(uri,test_pattern);
    Se verifica la correctitud sintáctica
    Si hay correctitud sintáctica entonces, se llama a la función parseHost
}

# Hace el trabajo que realiza el símbolo no terminal "H" de la gramática
function parseHost(url: string){
    # Se parsea el host
    local test_pattern = /(([a-z]+[a-z0-9\-]*[.])?([a-z0-9]+[a-z0-9\-]*[.])+[a-z]{2,3}|localhost)(:([0-9]{1,5}))?/;
    local results = split_all(url, test_pattern);
    Se verifica la correctitud sintáctica
    Si hay correctitud sintáctica entonces:
        Se almacena el host en uri$host
        Si existe una ruta entonces llamaremos a la función parsePath
}

# Hace el trabajo que realiza el símbolo no terminal "P" de la gramática
function parsePath(url: string){
    # Se parsea la ruta
    local test_pattern = /[^?#]*\/?/;
    local results = split_all(urlResult, test_pattern);
    Se verifica la correctitud sintáctica
    Si hay correctitud sintáctica entonces:
        Se llama a la función segmentarQuery
        Si existe un query, entonces llamaremos a la función parseQuery
        Si no existe un query, pero si un fragment, entonces llamaremos a la función parseFragment

}

# Hace el trabajo que realiza el símbolo no terminal " P' " de la gramática
function segmentarPath(path: string){

    local test_pattern = /\//;
    local results = split(url, test_pattern);
    parsedUri$path = results;
}

# Hace el trabajo que realiza el símbolo no terminal "Q" de la gramática
function parseQuery(url: string){
    # Se parsea el query
    local test_pattern = /\?[^#&]+((=[^#&]*)?(&[^#&]+(=[^#&]*)?)*)?/;
    local results = split_all(url, test_pattern);
    Se verifica la correctitud sintáctica
    Si hay correctitud sintáctica entonces:
        Se llama a la función segmentarQuery
        Si existe un fragment, entonces llamaremos a la función parseFragment

}

# Hace el trabajo que realiza el símbolo no terminal " Q' " de la gramática
function segmentarQuery(query: string){

    local queryUri : URI;
    # Se segmenta el query string.
    queryUri = decompose_uri(query);
    parsedUri$query = queryUri$params;
}

# Hace el trabajo que realiza el símbolo no terminal "F" de la gramática
function parseFragment(url: string){
    # Se parsea la ruta
    local test_pattern = /#.*/;
    local results = split_all(url, test_pattern);
    Se verifica la correctitud sintáctica
    Si hay correctitud sintáctica entonces:
        Se almacena el fragment en uri$fragment
}
\end{verbatim}

    Entonces, si se quiere poner en funcionamiento el módulo para segmentar de deberá llamar a la función “inicio” con un URL como parámetro de entrada.

\subsection{Implementación del la normalización de los URIs}

En la función de normalización que se encarga de hacer el trabajo descrito en la sección \ref{sec:normalizacion} se utiliza la hash table descrita en la sección ~\ref{sssec:estructuraNormalizacion} para realizar dicha la tarea.

Esta función tomará como output una variable de tipo string y mediante un loop for se itera por cada uno de las claves de la tabla (insertar numero de la hash table). Si alguna de los elementos está en el string que la función recibe como input, entonces se procederá a reemplazar dicho elemento por el valor que posee dicha clave en la hash table con la función “subst\_string” que proporciona Bro.

“subst\_string” es una función de la forma: function(s: string, from: string, to: string) : string

Se encarga de hacer sustituciones en una cadena de caracteres. Los parámetros de esta son:

\begin{itemize}
\item S: Cadena de caracteres en la que se efectúa la sustitución.
\item From: La cadena de caracteres que se va a buscar en “S” para ser sustituida.
\item To: Cadena de caracteres que pasará a sustituir a “From”.
\end{itemize}

A continuación se presenta la implementación de dicha función haciendo uso del lenguaje de scripting de Bro.

\begin{verbatim}

function normalizarUri(url: string): string {
    for (word in encoding){

        if (word in urlFinal){
            urlFinal = subst_string(urlFinal,word,encoding[word]);

        }
}
\end{verbatim}
        
\section{Implementación del modulo de evaluación}
En esta sección se explicará de manera detallada el modo en el que se implementó el módulo de evaluación explicado en la seccion \ref{sec:evaluacion}  haciendo uso de las herramientas otorgadas por Bro junto con las estructuras de datos utilizadas. El módulo de evaluación que a grandes rasgos se encarga de calcular el índice de anormalidad de un URI dado un modelo de normalidad para de esta manera evaluar si el mismo es anómalo o no. Esta evaluación se realizará comparando el índice de anormalidad con un parámetro $\theta$.

Para implementar lo que debe hacer el módulo de evaluación, se crearon dos grandes funcionalidades: una que se encargará de leer el modelo de normalidad y  otra que calculará el índice de anormalidad y evaluará si el mismo en anómalo o no. Ambas serán explicadas en las secciones presentadas a continuación.

\subsection{Estructura de datos}

El módulo de evaluación del sistema cuenta con varias estructura de datos compuestas de tipo “register” y de tipo “table”. La funcionalidad de leer el modelo de normalidad consta de dos estructuras de tipo “table” y dos de tipo “register”, mientras que la que se encarga de calcular el índice de normalidad cuenta con una sola estructura de tipo “table”.

\subsubsection{Lectura del modelo de normalidad}

Existen dos estructuras de tipo “register” en la función para leer el modelo de normalidad y dos de tipo “table”.
Las estructuras de tipo “register” poseen los siguientes campo:

La primera, cuyo nombre es “Word” posee los campos “word” y  “state”.

\begin{itemize}
\item “word” es un campo de tipo string en donde se almacenarán las palabras del vocabulario de cada uno de los estados del autómata presentado en la imagen \ref{fig:ssm}.
\item “state” es un campo de tipo string en donde se indicará el estado del autómata presentado en la imagen \ref{fig:ssm} al que pertenece la palabra almacenada en el campo “word”.
\end{itemize}

En Bro, esta estructura sería escrita de la siguiente forma:

\begin{verbatim}
    type Word: record {
            state: string;
            word: string;
    };
\end{verbatim}

La segunda estructura llamada “Probability” solo posee un campo llamado “probability”.

\begin{itemize}
\item “probability” es un campo de tipo “double” en donde se almacenará la probabilidad de generación de las palabras que se encuentran en el modelo.
\end{itemize}

La forma de esta estructura en el lenguaje de scripting de Bro sería la siguiente:
\begin{verbatim}
    type Probability: record {
            probability: double;
    };
\end{verbatim}

Por otra parte, las estructuras de tipo “table” son dos. Una tabla será utilizada para almacenar las palabras del vocabulario, la probabilidad de generación y el nombre del estado al que pertenece dicha información mientras que la otra almacenará las probabilidades de fuera de vocabulario de cada uno de los estados y el valor del parámetro $\theta$.

La primera tabla es una hash table que posee dos elementos tipo “string” como clave y como valor tiene un campo de tipo “Probability”. Un ejemplo de como luciría dicha estructura de datos en Bro seria la siguiente:

\begin{verbatim}
Btable: table[string,string] of Evaluacion::Probability;
\end{verbatim}

En “Btable” almacenará del modelo de normalidad las palabras del vocabulario, la probabilidad de generación de las mismas y el estado al que pertenece dicha información. Las claves de la misma serán las palabras del vocabulario y el nombre del estado al que pertenecen las mismas. Toda esta informacion será dada a través de un archivo de texto cuya estructura será explicada en las sección ~\ref{sec:lecturaModelo}.

La segunda tabla es una hash table que tendrá solo un elemento como clave de tipo “string”. Los valores de la misma serán campo tipo “Valor”. En Bro, dicha estructura luciria de la siguiente manera.

\begin{verbatim}
config : table[string] of Evaluacion::Valor;
\end{verbatim}

En la tabla “config” como se mencionó anteriormente se van a almacenar las probabilidades de fuera de vocabulario de cada uno de los estados del autómata y el parámetro $\theta$. La clave de la misma sería una cadena de caracteres que identifique cada una de las probabilidades  y el parámetro “theta”. Esas etiquetas serían las siguientes: Poov1, Poov2, Poov3, Poov4, Theta.  

Los campos “word”, “state” y “probability” no se almacenaron en una sola estructura ya que para leer el modelo de normalidad que estará almacenado en un archivo de texto se hizo uso de una herramienta otorgada por Bro que requiere que exista una estructura de datos  para las claves de la tabla que almacenará la información (en este caso “Btable”) y otra para los valores de la misma.

\subsubsection{Evaluación de las probabilidades de los URI}
La función  que se encarga de calcular el índice de anormalidad  y evaluar si el mismo es anómalo o no, solo contiene una estructura compuesta de tipo “record” y se utiliza junto a una herramienta de Bro que funciona para escribir logs. Los logs que son escritos a través de esta herramienta son archivos de texto que contiene una lista de los Uri que presenta anomalías.

La estructura lleva como nombre “InfoAtaque” y contiene los siguientes campos:

\begin{itemize}
\item clasificacion: es un campo de tipo “string” que almacena la clasificación de los URIs anómalos, es decir, aquí se indica si el mismo presenta anomalía por estar sintácticamente mal construidos o porque el índice de anormalidad sobrepasó el parámetro $\theta$.
\item uri: es un campo de tipo “string” en el que se va a almacenar el uri que va a ser registrado en el log.
\item probability: es un campo de tipo “string” en donde se va a almacenar el valor del índice de anormalidad del uri.
\end{itemize}

Todos los campos anteriormente descritos poseen la cualidad de ser de tipo “log” tambien. Con esto se indica cuál de los elementos de la estructura de datos se escribirá sobre los logs.

    El registro “InfoAtaque” escrito haciendo uso del lenguaje de scripting de Bro luciria de la siguiente forma:

\begin{verbatim}
    type InfoAtaque: record {
                clasificacion: string &log &default = "";
                uri : string &log &default = "";
                probability: string &log &default = "";
    }; 
\end{verbatim}

\subsection{Lectura del modelo en Bro}
\label{sec:lecturaModelo}
En esta sección se explicará cual es el formato de almacenamiento del modelo de normalidad y como se implementó la lectura del mismo. El modelo teórico que fue explicado en la sección (insertar número de la sección) posee elementos como: un conjunto “S” de estados, un conjunto “O” de símbolos observables que se encuentran en cada estado, una matriz “A” que contiene la probabilidad de transición entre estados, un conjunto “B” de vectores que contiene la probabilidad de las palabras observadas en cada estado y un vector de probabilidades iniciales. No obstante, los únicos elementos del modelo que se necesitan ingresar en sistema para que este funcione y realice las tareas de evaluación son: el conjunto “O” de símbolos observables que se encuentra en cada estado y el conjunto de vectores “B”. El conjunto “B” es necesario para resolver la ecuación (3.7 insertar etiqueta). Por otra parte, es necesario hacer uso tanto de “B” como “O” para obtener el valor de $b_{qtot}$ presentado en la ecuación (3.8 insertar etiqueta). Este elemento es sumamente importante para calcular el índice de anormalidad. Por otra parte, será necesario introducir al sistema los valores de probabilidad de fuera de vocabulario (Poov), ya que son necesarios para obtener el valor de $p_{qtot}$ en caso una cadena de caracteres del URI que se esté analizando no se encuentre en el conjunto de observaciones “O”. Además, se requiere el valor del parámetro $\theta$ para evaluar el índice de anormalidad según lo estipulado en la ecuación (3.6) .

    Entonces, en conclusión, los parámetros que requieren ser introducidos al sistema de detección de intrusiones para que este funcione de manera correcta son: el conjunto de observaciones de cada estado (O), el conjunto de vectores de probabilidad de las palabras observadas en cada estado ( $B_{S}, B_{P}, B_{A}, B_{V}$ ), los valores de probabilidad de fuera de vocabulario, es decir $P_{oovS}, P_{oovP}, P_{oovA}, P_{oovV}$ y el valor del parámetro $\theta$.

    *FORMATO*

Estos parámetros serán introducidos a través de dos archivos, un archivo llamado “config” que contendrá los valores de la probabilidad de fuera de vocabulario y el valor del parámetro $\theta$ y otro llamado “modeloBro.log” en el cual estará el conjunto de observaciones de cada estado junto a sus probabilidades de generación.

Tanto el archivo “config” como el “modeloBro.log” están regidos bajo un formato que establece la herramienta de Bro para leer archivos de entrada. Esta decisión fue tomada para poder utilizar dicha herramienta y así facilitar la lectura de ambos archivos.

El formato que establece Bro para los archivos de entrada define que la información se debe introducir en columnas separada mediante tabs, y que debe existir un encabezado al inicio del mismo que inicie abriendo con un numeral (\#) seguido de la palabra “fields”. Luego de esta palabra se escribirán los nombres que se le asignará a cada columna del archivo.

El formato del archivo “config”, es específico será el siguiente:

\begin{verbatim}
         #fields    clave    valor
         Poov1    0.0001
         Poov2    0.0001
         Poov3    0.0001
         Poov4    0.0001
         Theta    12.0
\end{verbatim}

La primera columna corresponde a las etiquetas que identifican los valores que se encuentran en la segunda columna. Es importante recalcar que los nombres “Poov1”, “Poov2”, “Poov3”, “Poov4” y “Theta” deben ser escritos en el archivo obligatoriamente de la misma forma en la que aparecen en el ejemplo.

\# Dar un ejemplo de como se almacena la información
La información que se encuentre en el archivo “config” será almacenada en  la tabla llamada “config” que fue explicada en la sección (introducir sección de las estructuras de dato). También es importante recalcar que los nombres de las columnas (“clave” y “valor” en este caso) deben corresponder con los nombres de los atributos de las estructuras de datos de tipo “register” llamada “Clave” y “Valor” presentada en la sección (introducir sección de las estructuras de dato)

Por otro lado, el formato del archivo “modeloBro.log” es el siguiente:

\begin{verbatim}
      #fields    state    word    probability
      #types    string    string    double
      Bss    192.168.1.13    1.0
      Bsp    idr    0.16759
      Bsa    idpd    0.000006
      Bsv    nombre    0.000175
      numeroPalabraSs    numTotal    205069.0
      numeroPalabraSp    numTotal    423870.0
      numeroPalabraSa    numTotal    319727.0
      numeroPalabraSv    numTotal    319727.0
\end{verbatim}

La segunda columna de este archivo (“word”) corresponde al conjunto de observaciones “O” de cada uno de los estados, mientras que la tercera columna (“probability”) indica la probabilidad de generación de cada palabra, es decir, esta columna almacena los datos de los vectores $B_{S}, B_{P}, B_{A}, B_{V}$. La primera columna (“state”), por otra parte indica a que estado del autómata pertenece cada palabra y su probabilidad de generación.

Las filas del archivo “modeloBro.log” que tienen en la primera columna las palabras:       “numeroPalabraSs”, “numeroPalabraSp”, “numeroPalabraSa”, “numeroPalabraSv” contienen el número de palabras que han sido procesadas por estado. Esta informacion será utilizada en el entrenamiento en modo offline que será explicado en la sección (insertar número de la sección del entrenamiento offline).

*MODO EN EL QUE SE LEEN LOS ARCHIVOS*

Una vez explicado el formato de los archivos que contienen los elementos del modelo y los parámetros necesarios para realizar el cálculo y la evaluación del índice de normalidad de los URIs a evaluar se procederá a explicar el funcionamiento de las funciones encargadas de leer los archivos con la información de entrada.

Para leer dicha informacion se hizo uso del  “input framework” que otorga Bro como herramienta para leer archivos de entrada y guardarla en tablas para que la misma pueda ser accedida de manera mas rapida y comoda dentro del código del programa. 

La función que se encarga de leer y almacenar en una tabla la información que está dentro de los archivos “config” y “modeloBro.log”  se llama $“add_table”$ y pertenece al módulo llamado “Input”.


%Extraido de : https://www.bro.org/sphinx/frameworks/input.html, https://www.bro.org/sphinx/scripts/base/frameworks/input/main.bro.html\#id-Input::add_table, https://www.bro.org/sphinx/scripts/base/frameworks/input/main.bro.html\#type-Input::TableDescription 
%
La misma tiene la siguiente forma: $Input::add_table(description: Input::TableDescription) : bool$ 

Donde $"Input::TableDescription"$ es una estructura de datos tipo “record” cuyos campos utilizados fueron los siguientes:

\begin{itemize}
\item source: campo de tipo “string” que almacena el nombre del archivo que va a ser leído.
\item name: campo de tipo “string” que almacenará el nombre el nombre que se le asignará al flujo de entrada.
\item destination: Nombre de la tabla que almacena la información contenida en los archivos.
\item idx: Nombre del registro que definirá los valores que utilizará la tabla que almacena la información del archivo como clave.
\item val: Campo opcional que almacena el nombre del registro que define los valores de la tabla que almacena la información de los archivos de entrada.
\end{itemize}

Un ejemplo concreto de cómo luciría esta función si se quieren leer los archivos “config” y “modeloBro.log” seria la siguiente:

La lectura del archivo “config” sería la siguiente:

\begin{verbatim}
Input::add_table([\$source=”config”, \$name=”config”,
                          \$idx=Clave, \$val=Valor,
                          \$destination=config]);
\end{verbatim}                    

Mientras que la lectura del archivo “modeloBro.log” se realizaría de la siguiente maner:

\begin{verbatim}
Input::add_table([\$source=”modeloBro.log”, \$name=”modeloBro”,
                          \$idx=Word, \$val=Probability,
                          \$destination=Btable]);
\end{verbatim}

Las tablas resultantes luego de leer ambos archivos serían las siguiente:

\begin{verbatim}
config = {   [Poov1] = 0.0001,
      [Poov2] =  0.0001,
      [Poov3] =  0.0001,
      [Poov4] =  0.0001,
                   [Theta]  =  12.0       };
\end{verbatim}

\begin{verbatim}
Btable = {      [Bss]  =  {192.168.1.13,    1.0}
      [Bsp]  =  {idr,    0.16759},
      [Bsa]  =  {idpd,    0.000006},
      [Bsv]  =  {nombre,    0.000175},
      [numeroPalabraSs]  = { numTotal,    205069.0},
      [numeroPalabraSp]  = {numTotal,    423870.0},
      [numeroPalabraSa]  =  {numTotal,    319727.0},
      [numeroPalabraSv]  =  {numTotal,    319727.0}      };
\end{verbatim}


\subsection{Evaluación de las probabilidades de los URI}
Explicar las funciones:
* evaluar{HostPath,Valores,Atributos}
* calcularIndiceAnormalidad
* verifiarAnomalia
\section{Implementación del modulo de entrenamiento}
\subsection{Estructura de datos}
\subsection{Entrenamiento Online}
\subsection{Entrenamiento Offline}
\subsection{Escritura del modelo de normalidad en Bro}